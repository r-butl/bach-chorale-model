{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_coconet_model(time_steps, pitches, num_instruments, num_layers=64, num_channels=128):\n",
    "    inputs = layers.Input(shape=(time_steps, pitches, num_instruments * 2))  # Includes mask as extra channels\n",
    "    x = inputs\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        x = layers.Conv2D(\n",
    "            filters=num_channels,\n",
    "            kernel_size=(3, 3),\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\"\n",
    "        )(x)\n",
    "        if i % 2 == 1:  # Add residual connections every second layer\n",
    "            x = layers.Add()([x, inputs if i == 1 else prev_x])\n",
    "        prev_x = x\n",
    "\n",
    "    # Final layer to predict pitch probabilities\n",
    "    x = layers.Conv2D(\n",
    "        filters=num_instruments, \n",
    "        kernel_size=(1, 1), \n",
    "        padding=\"same\", \n",
    "        activation=\"softmax\"\n",
    "    )(x)\n",
    "\n",
    "    model = models.Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_piano_roll(piano_roll, mask_prob=0.5):\n",
    "    \"\"\"\n",
    "    Applies random masking to a piano roll.\n",
    "    \"\"\"\n",
    "    mask = np.random.rand(*piano_roll.shape[:-1]) > mask_prob\n",
    "    masked_roll = np.where(mask[..., None], piano_roll, 0)\n",
    "    return masked_roll, mask[..., None]  # Return masked roll and mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(piano_rolls, mask_prob):\n",
    "    \"\"\"\n",
    "    Prepares input and target tensors with random masking.\n",
    "    \"\"\"\n",
    "    inputs, targets = [], []\n",
    "    for piano_roll in piano_rolls:\n",
    "        masked_roll, mask = mask_piano_roll(piano_roll, mask_prob)\n",
    "        # Concatenate mask and masked roll for input\n",
    "        inputs.append(np.concatenate([masked_roll, mask], axis=-1))\n",
    "        targets.append(piano_roll)\n",
    "    return np.array(inputs), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train_coconet(model, piano_rolls, epochs, batch_size, mask_prob_start, mask_prob_end):\n",
    "    optimizer = Adam()\n",
    "    loss_fn = CategoricalCrossentropy(from_logits=False)  # Using probabilities\n",
    "    steps_per_epoch = len(piano_rolls) // batch_size\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Linearly anneal masking probability\n",
    "        mask_prob = mask_prob_start + (mask_prob_end - mask_prob_start) * (epoch / epochs)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Masking Probability: {mask_prob:.2f}\")\n",
    "\n",
    "        for step in range(steps_per_epoch):\n",
    "            # Get batch\n",
    "            batch = piano_rolls[step * batch_size: (step + 1) * batch_size]\n",
    "\n",
    "            # Prepare inputs and targets\n",
    "            inputs, targets = preprocess_data(batch, mask_prob)\n",
    "\n",
    "            # Training step\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions = model(inputs, training=True)\n",
    "                loss = loss_fn(targets, predictions)\n",
    "            \n",
    "            # Backpropagation\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "            # Logging\n",
    "            print(f\"Step {step+1}/{steps_per_epoch}, Loss: {loss.numpy():.4f}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Dataset (Simulated)\n",
    "def generate_dummy_data(num_samples, time_steps, pitches, num_instruments):\n",
    "    \"\"\"\n",
    "    Generate a dummy piano roll dataset for testing.\n",
    "    \"\"\"\n",
    "    return np.random.randint(\n",
    "        0, 2, size=(num_samples, time_steps, pitches, num_instruments), dtype=np.int32\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731904765.429210   77665 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1133 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Inputs have incompatible shapes. Received shapes (128, 53, 128) and (128, 53, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m piano_rolls \u001b[38;5;241m=\u001b[39m generate_dummy_data(NUM_SAMPLES, TIME_STEPS, PITCHES, NUM_INSTRUMENTS)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_coconet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTIME_STEPS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPITCHES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_INSTRUMENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_LAYERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_CHANNELS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m, in \u001b[0;36mbuild_coconet_model\u001b[0;34m(time_steps, pitches, num_instruments, num_layers, num_channels)\u001b[0m\n\u001b[1;32m      6\u001b[0m     x \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mConv2D(\n\u001b[1;32m      7\u001b[0m         filters\u001b[38;5;241m=\u001b[39mnum_channels,\n\u001b[1;32m      8\u001b[0m         kernel_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m      9\u001b[0m         padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m         activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m     )(x)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# Add residual connections every second layer\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprev_x\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     prev_x \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Final layer to predict pitch probabilities\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/keras/src/layers/merging/base_merge.py:93\u001b[0m, in \u001b[0;36mMerge._compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m---> 93\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs have incompatible shapes. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         output_shape\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(output_shape)\n",
      "\u001b[0;31mValueError\u001b[0m: Inputs have incompatible shapes. Received shapes (128, 53, 128) and (128, 53, 8)"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "TIME_STEPS = 128      # Number of time steps (T)\n",
    "PITCHES = 53          # MIDI pitches 36 to 88\n",
    "NUM_INSTRUMENTS = 4   # Four-part harmony\n",
    "NUM_LAYERS = 64       # Total number of convolutional layers\n",
    "NUM_CHANNELS = 128    # Number of channels per layer\n",
    "EPOCHS = 10           # Number of epochs\n",
    "BATCH_SIZE = 32       # Batch size\n",
    "MASK_PROB_START = 0.75  # Initial masking probability\n",
    "MASK_PROB_END = 0.25    # Final masking probability\n",
    "NUM_SAMPLES = 1000    # Number of dummy samples\n",
    "\n",
    "# Generate dummy data\n",
    "piano_rolls = generate_dummy_data(NUM_SAMPLES, TIME_STEPS, PITCHES, NUM_INSTRUMENTS)\n",
    "\n",
    "# Build the model\n",
    "model = build_coconet_model(TIME_STEPS, PITCHES, NUM_INSTRUMENTS, NUM_LAYERS, NUM_CHANNELS)\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "train_coconet(model, piano_rolls, EPOCHS, BATCH_SIZE, MASK_PROB_START, MASK_PROB_END)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
